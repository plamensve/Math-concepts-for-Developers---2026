{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.363833400Z",
     "start_time": "2026-02-16T21:20:30.354323100Z"
    }
   },
   "source": [
    "from lib2to3.btm_utils import syms\n",
    "\n",
    "from sympy import resultant, symbols\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.371431800Z",
     "start_time": "2026-02-16T21:20:30.364834700Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import skimage.io\n",
    "# Write your imports here"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Exercise\n",
    "## Functions, Polynomials, Vectors, Matrices, Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. Polynomial Interpolation\n",
    "We know that if we have a set of $n$ data points with coordinates $(x_1; y_1), (x_2; y_2), \\dots, (x_n; y_n)$, we can try to figure out what function may have generated these points.\n",
    "\n",
    "Please note that **our assumptions about the data** will lead us to choosing one function over another. This means that our results are as good as our data and assumptions. Therefore, it's extremely important that we write down our assumptions (which sometimes can be difficult as we sometimes don't realize we're making them). It will be better for our readers if they know what those assumptions and models are.\n",
    "\n",
    "In this case, we'll state two assumptions:\n",
    "1. The points in our dataset are generated by a polynomial function\n",
    "2. The points are very precise, there is absolutely no error in them. This means that the function should pass **through every point**\n",
    "\n",
    "This method is called *polynomial interpolation* (*\"polynomial\"* captures assumption 1 and *\"interpolation\"* captures assumption 2).\n",
    "\n",
    "It can be proved (look at [Wikipedia](https://en.wikipedia.org/wiki/Polynomial_interpolation) for example) that if we have $n$ data points, there is only one polynomial of degree $n-1$ which passes through them. In \"math speak\": \"the vector spaces of $n$ points and polynomials of degree $n-1$ are isomorphic (there exists a bijection mapping one to the other)\".\n",
    "\n",
    "There are a lot of ways to do interpolation. We can also write the function ourselves if we want but this requires quite a lot more knowledge than we already covered in this course. So we'll use a function which does this for us. `numpy.polyfit()` is one such function. It accepts three main parameters (there are others as well, but they are optional): a list of $x$ coordinates, a list of $y$ coordinates, and a polynomial degree.\n",
    "\n",
    "Let's say we have these points:\n",
    "```python\n",
    "points = np.array([(0, 0), (1, 0.8), (2, 0.9), (3, 0.1), (4, -0.8), (5, -1.0)])\n",
    "```\n",
    "\n",
    "First, we need to \"extract\" the coordinates:\n",
    "```python\n",
    "x = points[:, 0]\n",
    "y = points[:, 1]\n",
    "```\n",
    "\n",
    "Then, we need to calculate the interpolating polynomial. For the degree, we'll initially set $n-1$:\n",
    "```python\n",
    "poly = np.polynomial.polynomial.Polynomial.fit(...)\n",
    "# TODO: Find a way to make the line shorter; call the correct arguments\n",
    "```\n",
    "\n",
    "After that, we need to plot the function. To do this, we'll create a range of $x$ values and evaluate the polynomial at each value:\n",
    "```python\n",
    "plot_x = np.linspace(np.min(x), np.max(x), 1000) # If you want, pass the number of points as a parameter\n",
    "plot_y = poly(plot_x)\n",
    "```\n",
    "\n",
    "Finally, we need to plot the result. We'll plot both the fitting polynomial curve (using `plt.plot()`) and the points (using `plt.scatter`). It's also nice to have different colors to make the line stand out from the points.\n",
    "```python\n",
    "plt.plot(plot_x, plot_y, c = \"green\")\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "```\n",
    "Don't forget to label the axes!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.381015900Z",
     "start_time": "2026-02-16T21:20:30.374431200Z"
    }
   },
   "source": [
    "# Write your code here"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to **wrap the code in a function**. It should accept a list of points, the polynomial degree, min and max value of $x$ used for plotting. \n",
    "\n",
    "**Be extremely careful to ensure that the function uses its parameters!** Of course, you can extract other utility functions if you wish (e.g., separating plotting from the rest is a good idea).\n",
    "\n",
    "We'll use this function to try some other cases."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.397174400Z",
     "start_time": "2026-02-16T21:20:30.386014700Z"
    }
   },
   "source": [
    "def interpolate_polynomial(points, degree, min_x, max_x):\n",
    "    \"\"\"\n",
    "    Interpolates a polynomial of the specified degree through the given points and plots it\n",
    "    points - a list of points (x, y) to plot\n",
    "    degree - the polynomial degree\n",
    "    min_x, max_x - range of x values used to plot the interpolating polynomial\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.406711500Z",
     "start_time": "2026-02-16T21:20:30.397174400Z"
    }
   },
   "source": [
    "points = np.array([(0, 0), (1, 0.8), (2, 0.9), (3, 0.1), (4, -0.8), (5, -1.0)])\n",
    "interpolate_polynomial(points, len(points) - 1, np.min(points[:, 0]), np.max(points[:, 0]))"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see this is a very nice fit. This is expected, of course. Let's try to expand our view a little. Let's try to plot other values of $x$, further than the original ones. This is **extrapolation**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.431504900Z",
     "start_time": "2026-02-16T21:20:30.413219500Z"
    }
   },
   "source": [
    "interpolate_polynomial(points, len(points) - 1, -5, 10)"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... it seems our polynomial goes a little wild outside the original range. This is to show how **extrapolation can be quite dangerous**.\n",
    "\n",
    "Let's try a lower polynomial degree now. We used 4, how about 3, 2 and 1?\n",
    "**Note:** We can add titles to every plot so that we know what exactly we're doing. Te title may be passed as an additional parameter to our function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.452090900Z",
     "start_time": "2026-02-16T21:20:30.432507200Z"
    }
   },
   "source": [
    "interpolate_polynomial(points, 3, np.min(points[:, 0]), np.max(points[:, 0]))\n",
    "interpolate_polynomial(points, 2, np.min(points[:, 0]), np.max(points[:, 0]))\n",
    "interpolate_polynomial(points, 1, np.min(points[:, 0]), np.max(points[:, 0]))"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the fitting curves (or line in the last case) struggle more and more and they don't pass through every point. This breaks our assumptions but it can be very useful.\n",
    "\n",
    "Okay, one more thing. How about increasing the degree? Let's try 5, 7 and 10. Python might complain a little, just ignore it, everything is fine... sort of :)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.465115200Z",
     "start_time": "2026-02-16T21:20:30.454091800Z"
    }
   },
   "source": [
    "interpolate_polynomial(points, 5, np.min(points[:, 0]), np.max(points[:, 0]))\n",
    "interpolate_polynomial(points, 7, np.min(points[:, 0]), np.max(points[:, 0]))\n",
    "interpolate_polynomial(points, 10, np.min(points[:, 0]), np.max(points[:, 0]))"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those graphs look pretty much the same. But that's the point exactly. I'm being quite sneaky here. Let's try to expand our view once again and see what our results really look like."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.475631500Z",
     "start_time": "2026-02-16T21:20:30.466115600Z"
    }
   },
   "source": [
    "interpolate_polynomial(points, 5, -10, 10)\n",
    "interpolate_polynomial(points, 7, -10, 10)\n",
    "interpolate_polynomial(points, 10, -10, 10)"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see there are very wild differences. Even though the first two plots look quite similar, look at the $y$ values - they're quite different.\n",
    "\n",
    "So, these are the dangers of interpolation. Use a too high degree, and you get \"the polynomial wiggle\". These are all meant to represent **the same** data points but they look insanely different. Here's one more comparison."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.493840700Z",
     "start_time": "2026-02-16T21:20:30.482148500Z"
    }
   },
   "source": [
    "interpolate_polynomial(points, len(points) - 1, -2, 7)\n",
    "interpolate_polynomial(points, len(points) + 1, -2, 7)"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see what big difference even a small change in degree can make. This is why we have to choose our interpolating functions very carefully. Generally, a lower degree means a simpler function, which is to be preferred. See [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this, let's use the following set of points. What degree do you think would be the most reasonable? What are the coefficents of the interpolation?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.506505600Z",
     "start_time": "2026-02-16T21:20:30.500345800Z"
    }
   },
   "source": [
    "points = np.array([(1, 0.5), (2, 3), (3, 2), (4, -1), (5, 1.5)])\n",
    "# TODO: Write your code here"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add one more point. What can you observe now?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.515204100Z",
     "start_time": "2026-02-16T21:20:30.509163100Z"
    }
   },
   "source": [
    "points = np.array([(1, 0.5), (2, 3), (3, 2), (4, -1), (5, 1.5), (6, 23)])\n",
    "# TODO: Write your code here"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, **we need to be very careful about our assumptions**. Have a look at this situation:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.524508200Z",
     "start_time": "2026-02-16T21:20:30.517204400Z"
    }
   },
   "source": [
    "points = np.array([(-5, 0.03846), (-4, 0.05882), (-3, 0.1), (-2, 0.2), (-1, 0.5), (0, 1), (1, 0.5), (2, 0.2), (3, 0.1), (4, 0.05882), (5, 0.03846)])\n",
    "interpolate_polynomial(points, len(points) - 1, np.min(points[:, 0]), np.max(points[:, 0]))"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot definitely looks strange... This is because the generating function is not a polynomial. It's actually:\n",
    "$$ y = \\frac{1}{1 + x^2} $$\n",
    "\n",
    "Plot the polynomial interpolation and the real generating function **on the same plot**. You may need to modify the original plotting function or just copy its contents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.533018800Z",
     "start_time": "2026-02-16T21:20:30.525508Z"
    }
   },
   "source": [
    "# Write your code here"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Run-length Encoding\n",
    "One application of algebra and basic math can be **compression**. This is a way to save data in less space than it originally takes. The most basic form of compression is called [run-length encoding](https://en.wikipedia.org/wiki/Run-length_encoding).\n",
    "\n",
    "Write a function that encodes a given text. Write another one that decodes.\n",
    "\n",
    "We can see that RLE is not very useful in the general case. But it can be extremely useful if we have very few symbols. An example of this can be DNA and protein sequences. DNA code, for example, has only 4 characters.\n",
    "\n",
    "Test your encoding and decoding functions on a DNA sequence (you can look up some on the Internet). Measure how much your data is compressed relative to the original."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:54.736603600Z",
     "start_time": "2026-02-16T21:20:54.729429800Z"
    }
   },
   "source": [
    "from collections import deque\n",
    "def encode(text):\n",
    "    d = deque(list(text))\n",
    "    first_symb = d.popleft()\n",
    "    result = []\n",
    "\n",
    "    current_symbol = f'{first_symb}'\n",
    "    while d:\n",
    "        symb = d.popleft()\n",
    "\n",
    "        if current_symbol[-1] != symb:\n",
    "            result.append((current_symbol[-1], len(current_symbol)))\n",
    "            current_symbol = ''\n",
    "            current_symbol += symb\n",
    "        else:\n",
    "            current_symbol += symb\n",
    "\n",
    "        if not d:\n",
    "            result.append((current_symbol[-1], len(current_symbol)))\n",
    "            break\n",
    "\n",
    "    return ''.join(f\"{char}{count}\" if count > 1 else char for char, count in result)\n",
    "\n",
    "def decode(text):\n",
    "    \"\"\"\n",
    "    Decodes the text using run-length encoding\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T21:20:30.585327600Z",
     "start_time": "2026-02-16T21:20:30.551977900Z"
    }
   },
   "source": [
    "# Tests\n",
    "# Test that the functions work on their own\n",
    "assert encode(\"AABCCCDEEEE\") == \"A2BC3DE4\"\n",
    "assert decode(\"A2BC3DE4\") == \"AABCCCDEEEE\"\n",
    "\n",
    "# Test that the functions really invert each other\n",
    "assert decode(encode(\"AABCCCDEEEE\")) == \"AABCCCDEEEE\"\n",
    "assert encode(decode(\"A2BC3DE4\")) == \"A2BC3DE4\""
   ],
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[53]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Tests\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# Test that the functions work on their own\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m encode(\u001B[33m\"\u001B[39m\u001B[33mAABCCCDEEEE\u001B[39m\u001B[33m\"\u001B[39m) == \u001B[33m\"\u001B[39m\u001B[33mA2BC3DE4\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m decode(\u001B[33m\"\u001B[39m\u001B[33mA2BC3DE4\u001B[39m\u001B[33m\"\u001B[39m) == \u001B[33m\"\u001B[39m\u001B[33mAABCCCDEEEE\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# Test that the functions really invert each other\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m decode(encode(\u001B[33m\"\u001B[39m\u001B[33mAABCCCDEEEE\u001B[39m\u001B[33m\"\u001B[39m)) == \u001B[33m\"\u001B[39m\u001B[33mAABCCCDEEEE\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mAssertionError\u001B[39m: "
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Problem 3 Function Invertibility and Cryptography\n",
    "As we already saw, some functions are able to be inverted. That is, if we know the output, we can see what input generated it directly. This is true if the function is **one-to-one correspondence** (bijection).\n",
    "\n",
    "However, not all functions are created the same. Some functions are easy to compute but their inverses are extremely difficult. A very important example is **number factorization**. It's relatively easy (computationally) to multiply numbers but factoring them is quite difficult. Let's run an experiment. We'll also get to know what _performance testing_ is, which is really useful when we work with huge amounts of data. \n",
    "\n",
    "We'll need a function to generate random n-bit numbers. One such function can be found in the `random` package:\n",
    "```python\n",
    "import random\n",
    "random.getrandbits(n_bits)\n",
    "```\n",
    "\n",
    "It works perfectly for this example. However, to make a point about random generators and their security, we may want to import a similar function from the `secrets` module instead. If you're interested, you can look up \"cryptographic pseudo-random number generators\" / \"PRNGs\".\n",
    "```python\n",
    "import secrets\n",
    "secrets.randbits(n_bits)\n",
    "\n",
    "```\n",
    "\n",
    "We could, of course, write our factorization by hand but we'll use `sympy`\n",
    "```python\n",
    "from sympy.ntheory import factorint\n",
    "factorint(1032969399047817906432668079951) # {3: 2, 79: 1, 36779: 1, 7776252885493: 1, 5079811103: 1}\n",
    "```\n",
    "\n",
    "This function returns a `dict` where the keys are the factors, and the values - how many times they should be multiplied.\n",
    "\n",
    "We'll also need a tool to accurately measure performance. Have a look at [this one](https://docs.python.org/3/library/time.html#time.time) for example; although you may find a more accurate function.\n",
    "\n",
    "Specify a sequence of _bit lengths_ (`n_bits`), in increasing order. For example, you might choose something like `[10, 20, 25, 30, 32, 33, 35, 38, 40]`. Depending on your computing power you can go as high as you want. For each bit length, generate a number. See how much time it takes to factor it. Then see how much time it takes to multiply the factors. Be careful how you measure these. You shouldn't include the number generation (or any other external functions) in your timing. For better results, you may want to generate many numbers for every bit length and average the results.\n",
    "\n",
    "In order to have better accuracy, don't do this once per bit length. Do it, for example, five times, and average the results.\n",
    "\n",
    "Plot all multiplication and factorization times as a function of the number of bits. You should see that factorization is much, much slower. If you don't see this, just try larger numbers :D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. Basis Vectors in 2D Coordinate Space\n",
    "We know that for an n-dimensional vector space, we need **exactly n** vectors to form a basis. Let's visualize that.\n",
    "\n",
    "The function you wrote last time for visualizing complex numbers can be extended to visualize any set of vectors. If you haven't already written that, have a look at [this StackOverflow post](https://stackoverflow.com/questions/12265234/how-to-plot-2d-math-vectors-with-matplotlib). You need to use the `quiver()` function. Pay attention to its parameters so you use it correctly!\n",
    "\n",
    "Write a function which accepts an array of vectors in the format `[start_x, start_y, end_x, end_y]` and plots them. Optionally, you can add different colors. When you call `quiver()` pass `color = colors` as the last parameter and it will take care of them.\n",
    "\n",
    "Make sure to leave enough space on the axes. `quiver()` doesn't resize the plot area automatically to fit everything. You can do this manually. A simple `plt.xlim(-10, 10)` and `plt.ylim(-10, 10)` will do the job but you can do much better if you wish :)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_vectors(vectors, colors):\n",
    "    \"\"\"\n",
    "    Plots vectors on the xy-plane. The `vectors` parameter is a Python list.\n",
    "    Each vector is specified in the format [start_x, start_y, end_x, end_y]\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_vectors([[0, 0, 2, 3]], [\"red\"]) # One vector\n",
    "plot_vectors([[0, 0, 1, 0], [0, 0, 0, 1]], [\"red\", \"blue\"]) # Two orthogonal vectors\n",
    "plot_vectors([[1, 1, -2, 3], [2, 1, -2.5, 1.5], [-3.2, -1.5, 0, 4.3]], [\"red\", \"blue\", \"orange\"]) # Three arbitrary vectors"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that any 2 linearly independent vectors can form a basis in 2D space. This means that every other vector can be represented as their linear combination. It will be easiest to see this in the standard basis of 2D space.\n",
    "\n",
    "We start by defining the two basis vectors: $e_1, e_2$. Then, we choose an arbitrary vector $v$. We know that it can be expressed as a linear combination $$ v = \\lambda_1e_1 + \\lambda_2e_2 $$\n",
    "\n",
    "Finding the unknown coefficients is the same as solving a linear system with as many equations as there are basis vectors (2 in this case). We can do this by using `np.linalg.solve()`.\n",
    "\n",
    "**Note:** If you want to write `lambda` in Python for some reason, use the variable name `lamda` since `lambda` is a reserved keyword."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def find_linear_combination_coefficients(e1, e2, v):\n",
    "    \"\"\"\n",
    "    Returns the coordinates of the representation of v in the basis {e_1, e_2}.\n",
    "    That is, the unknown coefficients in the linear combination v = lambda_1 * e_1 + lambda_2 * e_2\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "e1, e2 = [[1, 0], [0, 1]]\n",
    "v = [3.5, 8.6]\n",
    "# Find the unknown coefficients. Extract the logic in a function.\n",
    "# It should accept the two basis vectors and the one we need to represent\n",
    "# and should return the two coefficients\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "# Plot the three vectors\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficents should be the same as the vector's coordinates. That's because we were extremely careful in choosing a basis.\n",
    "\n",
    "We know, however, that any pair of linearly independent vectors forms a basis in 2D space. So, let's try this.\n",
    "\n",
    "Choose two arbitrary vectors (in the code they are `[2, 3]` and `[-5, 1]` but feel free to change them as you wish). Represent $v$ as their linear combination and print the coefficients. After that, plot the resulting vectors to verify visually that the third one is the linear combination of the other two with the coefficients that you saw."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "e1, e2 = [[2, 3], [-5, 1]]\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did was **changing the basis**. We represented **the same original vector $v$** in the new coordinates. We didn't change the geometric object $v$ itself; it still looks the same in the plot. We only changed our viewpoint. This is what change of basis is all about: changing viewpoints.\n",
    "\n",
    "Let's also see what an \"orthogonal\" basis is: the basis vectors are orthogonal to each other. You can find online how to compute orthogonal vectors but we don't need that. A definition of orthogonal vectors is: a set of two vectors $a, b$ such that $a.b = 0$. One such set of vectors is `[3, 4], [-4, 3]`.\n",
    "\n",
    "Represent the same vector $v$ in the orthogonal basis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "e1, e2 = [[3, 4], [-4, 3]]\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a more visually pleasing basis: one whose basis vectors are **collinear** (parallel) to the coordinate axes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "e1, e2 = [[0, 5], [4, 0]]\n",
    "coefficients = find_linear_combination_coefficients(e1, e2, v)\n",
    "print(\"Coefficients: \", str(coefficients))\n",
    "plot_vectors([[0, 0, i[0], i[1]] for i in [e1, e2, v]], [\"red\", \"blue\", \"green\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've seen the coordinates of $v$ in different **bases** (plural form of \"basis\"). You can see that algebra doesn't really care what the basis vectors are. We simply need *some* point of reference.\n",
    "\n",
    "You can also see the transition from an arbitrary basis, to an orthogonal basis, to an orthonormal basis, to the standard basis (which is orthonormal **AND** aligned to the xy axes). You can also see that the standard basis gives us the easiest possible representation of a vector. That's why it's so useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5. Vectorization in `numpy`\n",
    "As programmers, we're used to writing for-loops to iterate over collections. This is quite OK but in Python makes the code slow (because it's an interpreted, dynamically-typed language). For example, a \"standard\" way of summing an array would be\n",
    "```python\n",
    "x = [2, 3, 8, -2.3, 0, 15]\n",
    "python_sum = 0\n",
    "for i in range(len(x)):\n",
    "    python_sum += x[i]\n",
    "print(python_sum)\n",
    "```\n",
    "\n",
    "However, there are better ways to do this. `numpy` works in C \"behind the scenes\". This means that:\n",
    "1. Operations in C are very, very, VERY fast\n",
    "2. Communication between C and Python is slow\n",
    "\n",
    "This means we should prepare our code to use `numpy` arrays as much as possible. First of all, this gives us a great computational advantage: the code is very fast. Second, it will look simpler and more beautiful. Compare the previous code with this one:\n",
    "```python\n",
    "x = [2, 3, 8, -2.3, 0, 15]\n",
    "numpy_sum = np.sum(x)\n",
    "print(numpy_sum)\n",
    "```\n",
    "\n",
    "Of course, the for-loop is still done, it's just hidden.\n",
    "\n",
    "The basic rule is **whenever possible, avoid looping and use vectors and matrices**. Sometimes it's impossible to avoid loops and that's OK.\n",
    "\n",
    "Let's create a performance test. Create a large array of random numbers. You can use `np.random.random()`. Sum the array using `numpy` and using the for-loop. Compare the times. In some cases, the performance difference will be several hundred times (e.g. length = $1.10^7$, difference $\\approx 2000$ times: $\\approx 0.01ms$ for the `sum()` and $\\approx 2s$ for the loop).\n",
    "\n",
    "Don't forget to see that the sums are equal. A fast but incorrect algorihm is not an option :).\n",
    "\n",
    "Next, call the function for different lengths and create two plots showing the time it takes to multiply different-length arrays. **Idea:** You can plot them on two separate y-axes on the same plot. Look at the `twiny()` function. See how much time it takes to perform both operations.\n",
    "\n",
    "Plot another plot: speedup versus length. Plot the length on the x-axis and the speedup (`np_sum_time / for_loop time`) on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one slight warning to using vectors. If we don't know what we're doing we might get very hard-to-detect bugs.\n",
    "\n",
    "Let's look at vector multiplication. In algebra we may write:\n",
    "$$ \\begin{bmatrix}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}.\n",
    " \\begin{bmatrix}\n",
    "5 \\\\\n",
    "-2 \\\\\n",
    "3\n",
    "\\end{bmatrix}=16$$\n",
    "\n",
    "This is the same as\n",
    "$$ \\begin{bmatrix}\n",
    "2 & 3 & 4\n",
    "\\end{bmatrix}.\n",
    " \\begin{bmatrix}\n",
    "5 & -2 & 3\n",
    "\\end{bmatrix}=16$$\n",
    "\n",
    "In vector multiplication, rows and columns don't really matter. However, most of the time we want to use **the matrix convention**: \"rows times columns\". This means that both products above are undefined. Also, the inner product is\n",
    "$$ \\begin{bmatrix}\n",
    "2 & 3 & 4\n",
    "\\end{bmatrix}\n",
    ".\n",
    " \\begin{bmatrix}\n",
    "5 \\\\\n",
    "-2 \\\\\n",
    "3\n",
    "\\end{bmatrix}=16$$\n",
    "\n",
    "The inverse operation, following our convention, will return a matrix (this is called **outer product**):\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4\n",
    "\\end{bmatrix}.\n",
    " \\begin{bmatrix}\n",
    "5 & -2 & 3\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "10 & -4 & 6 \\\\\n",
    "15 & -6 & -9 \\\\\n",
    "20 & -8 & 12\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Let's compare how the default `numpy` behaviour does and how we can impose our convention.\n",
    "\n",
    "First, let's create the arrays. Next, multiply them. Everything should look fine... until we look at the shapes of `x` and `y` which are `(3,)`. This kind of array is called **rank-1 array**. The matrix convention **DOES NOT** apply to it. One big error is evident when we try to transpose them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = np.array([2, 3, 4])\n",
    "y = np.array([5, -2, 3])\n",
    "print(\"x.y =\", str(x.dot(y)))\n",
    "\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"x:\", x)\n",
    "print(\"x transpose:\", x.T)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposition **DID NOT** turn our row-vector into a column vector! This is correct but **does not follow the matrix convention**.\n",
    "\n",
    "How do we follow the matrix convention then? Simple, just represent the vectors as matrices (2D arrays)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = np.array([[2, 3, 4]]) # Row vector\n",
    "y = np.array([[5], [-2], [3]]) # Column vector\n",
    "\n",
    "print(\"x.shape:\", x.shape)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"x.y:\\n\", x.dot(y)) # Dot product -> still looks like a matrix\n",
    "print(\"y.x:\\n\", y.dot(x)) # Outer product -> matrix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple convention can save us a lot of trouble in the future, especially when dealing with more complicated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6. Visualizing Linear Transformations\n",
    "Write a code which visualizes a linear transformation. It should show \"the old space\" and \"the new space\" imposed on it.\n",
    "\n",
    "Actually, if you don't want to write the code, I've already provided something for you. The following cell contains the `visualize_transform.py` code from last time. We'll examine it and see how we can use it to show our own transformations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def visualize_transformation(matrix, plot_title):\n",
    "    fig = plt.figure()\n",
    "    plt.axis(\"equal\")\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # Limits, labels and grid\n",
    "    ax.set_xlim(-5, 5)\n",
    "    ax.set_ylim(-5, 5)\n",
    "    ax.set_xticks(np.arange(ax.get_xlim()[0], ax.get_xlim()[1] + 1))\n",
    "    ax.set_yticks(np.arange(ax.get_ylim()[0], ax.get_ylim()[1] + 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid()\n",
    "    ax.set_title(plot_title)\n",
    "\n",
    "    # Unit vectors\n",
    "    ax.quiver([0, 0], [0, 0], [1, 0], [0, 1], color = [\"red\", \"blue\"], alpha = 0.2, units = \"xy\", scale = 1)\n",
    "\n",
    "    # Transformation\n",
    "    matrix = [\n",
    "        [matrix[0][0], matrix[0][1], 0],\n",
    "        [matrix[1][0], matrix[1][1], 0],\n",
    "        [0, 0, 1],\n",
    "    ]\n",
    "    t = Affine2D(matrix)\n",
    "\n",
    "    [min_x, max_x, min_y, max_y] = [2 * ax.get_xlim()[0], 2 * ax.get_xlim()[1] + 1, 2 * ax.get_ylim()[0], 2 * ax.get_ylim()[1] + 1]\n",
    "\n",
    "    # New (transformed) grid lines\n",
    "    # Horizontal\n",
    "    for y in np.arange(min_y, max_y):\n",
    "        ax.plot([min_x, max_x], [y] * 2, color = \"red\", linestyle = \"--\", linewidth = 2, transform = t + ax.transData)\n",
    "    # Vertical\n",
    "    for x in np.arange(min_x, max_x):\n",
    "        ax.plot([x] * 2, [min_y, max_y], color = \"blue\", linestyle = \"--\", linewidth = 2, transform = t + ax.transData)\n",
    "\n",
    "    # New (transformed) unit vectors\n",
    "    new_x = t.transform_affine([1, 0])\n",
    "    new_y = t.transform_affine([0, 1])\n",
    "    ax.quiver([0, 0], [0, 0], [new_x[0], new_y[0]], [new_x[1], new_y[1]], color = [\"red\", \"blue\"], units = \"xy\", angles = \"xy\", scale = 1)\n",
    "   \n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is mostly \"housekeeping\" - making the plot look nicer. It basically consits of several parts:\n",
    "1. Visualize gridlines\n",
    "2. Create the transformation from the matrix: `t = Affine2D(matrix)`\n",
    "3. Visualize transformed gridlines\n",
    "\n",
    "A quirk with `Affine2D()` is that it uses a 3x3 matrix. What's more, the last row is always `[0, 0, 1]`. This is because the third column corresponds to moving (translation) of the entire coordinate system. As you can imagine, this doesn't leave the origin fixed, therefore **translation is not a linear transformation**. It's an affine transformation, which is exactly what the code does. More info [here](https://stackoverflow.com/questions/10698962/why-do-2d-transformations-need-3x3-matrices).\n",
    "For our purposes, we defined the 2D transformation matrix as:\n",
    "$$ T=\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix} $$\n",
    "which we'll pass to the function as\n",
    "$$ T=\\begin{bmatrix}\n",
    "a & b & 0 \\\\\n",
    "c & d & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "**Note:** If you want to visualize translations, feel free to do so.\n",
    "\n",
    "Let's see what various transformations look like."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Identity\n",
    "matrix = [\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Identity\\ transformation}$\")\n",
    "\n",
    "# Scaling\n",
    "matrix = [\n",
    "    [2, 0],\n",
    "    [0, 1]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Scaling}$\")\n",
    "\n",
    "# Shear\n",
    "matrix = [\n",
    "    [1, 2],\n",
    "    [-1, 1]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Shear}$\")\n",
    "\n",
    "# Rotation\n",
    "matrix = [\n",
    "    [np.cos(np.radians(30)), -np.sin(np.radians(30))],\n",
    "    [np.sin(np.radians(30)), np.cos(np.radians(30))]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{30^{\\circ}\\ rotation}$\")\n",
    "\n",
    "# Projection (linearly dependent rows)\n",
    "matrix = [\n",
    "    [1, 2],\n",
    "    [2, 4]\n",
    "]\n",
    "\n",
    "visualize_transformation(matrix, r\"$\\mathrm{Projection\\ (linearly\\ dependent\\ rows)}$\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to experiment with other matrices and to see what transformation they will result in. Also feel free to write better visualization code."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7. Images as Matrices. Image arithmetic\n",
    "One direct use of matrices and transformations is images. An image is a 2D array (i.e. matrix) of pixels. If it's grayscale, each pixel will be an integer from 0 to 255:\n",
    "$$ I=\\begin{bmatrix}\n",
    "20 & 45 & 83 & \\dots \\\\\n",
    "38 & 182 & 200 & \\dots \\\\\n",
    "\\dots & \\dots & \\dots & \\dots \\\\\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "In an RGB image, each pixel contains three values, corresponding to $R$, $G$ and $B$.\n",
    "\n",
    "A bigger number means more brightness in the corresponding channel, for example `[255, 0, 0]` is a completely red pixel. `[0, 0, 0]` is a black pixel, and `[255, 255, 255]` is a white pixel.\n",
    "\n",
    "Because we treat images as matrices, we can peform arithmetic operations on them.\n",
    "\n",
    "To show an image, you can use `plt.imshow()`.\n",
    "\n",
    "#### Opening an image from the Internet\n",
    "This one proves not to be easy. However, there's a library for working with images called `scikit-image` which solves most of our problems. Even better, it returns a `numpy` array, which is perfect for us."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read_image(url):\n",
    "    img = skimage.io.imread(url)\n",
    "    return img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cat_image_url = \"https://d17fnq9dkz9hgj.cloudfront.net/uploads/2012/11/140272627-grooming-needs-senior-cat-632x475.jpg\"\n",
    "cat_image = read_image(cat_image_url)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cat_image[0][0] # First pixel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.imshow(cat_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, it's useful to treat the channels one by one."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cat_image_r, cat_image_g, cat_image_b = [cat_image[:, :, i] for i in range(3)]\n",
    "f, (ax_r, ax_g, ax_b) = plt.subplots(1, 3, figsize = (10, 5))\n",
    "ax_r.imshow(cat_image_r, cmap = \"gray\")\n",
    "ax_r.set_title(\"Red channel\")\n",
    "ax_g.imshow(cat_image_g, cmap = \"gray\")\n",
    "ax_g.set_title(\"Green channel\")\n",
    "ax_b.imshow(cat_image_b, cmap = \"gray\")\n",
    "ax_b.set_title(\"Blue channel\")\n",
    "plt.setp([ax_r, ax_g, ax_b], xticks = [], yticks = []) # Remove axis ticks\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we simply add the channels together, without making them red, green or blue, we'll get a grayscale image. Note that this doesn't appear very pleasing. This is because the human eye perceives different colors differently.\n",
    "\n",
    "Note that we first need to \"normalize\" each channel, that is, divide by 255. This will rescale all values. Instead of $[0; 255]$, they'll be in the range $[0; 1]$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cat_image_r_normalized, cat_image_g_normalized, cat_image_b_normalized = [\n",
    "    channel / 255 for channel in [cat_image_r, cat_image_g, cat_image_b]\n",
    "] \n",
    "cat_image_gray = (cat_image_r_normalized + cat_image_g_normalized + cat_image_b_normalized) / 3.0  \n",
    "plt.imshow(cat_image_gray, cmap = \"gray\")\n",
    "plt.title(\"Average grayscale image\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eye is more sensitive to greens than reds or blues. There are several ways to apply that correction, but we'll use [this one](https://stackoverflow.com/questions/14330/rgb-to-monochrome-conversion). This is called **luminance correction** (or **gamma correction**)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cat_image_gray_corrected = (0.299 * cat_image_r_normalized + \n",
    "                            0.587 * cat_image_g_normalized + \n",
    "                            0.114 * cat_image_b_normalized)\n",
    "plt.gca().imshow(cat_image_gray_corrected, cmap = plt.cm.gray)\n",
    "plt.title(\"Gamma-corrected grayscale image\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to create an artistic grayscale image, we can always change the coefficients. Feel free to experiment with this.\n",
    "\n",
    "So, there we go. We just performed matrix operations on images. Later, we'll talk about matrix multiplication and convolution, which is a very cool way of processing images.\n",
    "\n",
    "For the time being, let's just try one more thing. The **image histogram** will give us information of how bright our image is. On the x-axis, there are pixel values from 0 to 255. On the y-axis, there is the count of all values, for example 10 pixels with value 0, 30 pixels with value 1 and so on."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.hist(cat_image_gray.ravel(), bins = 256, color = \"black\")\n",
    "plt.title(\"Uncorrected image histogram\")\n",
    "plt.show()\n",
    "plt.hist(cat_image_gray_corrected.ravel(), bins = 256, color = \"red\")\n",
    "plt.title(\"Corrected image histogram\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Represent the image as a single-dimensional vector\n",
    "hist_vector = cat_image_gray.ravel()\n",
    "\n",
    "# Normalize the image to have values in the range [0; 1]\n",
    "hist_vector = hist_vector / (hist_vector.max() - hist_vector.min())\n",
    "\n",
    "plt.hist(hist_vector, bins = 256, color = \"black\", alpha = 0.5, label = \"Uncorrected\")\n",
    "plt.hist(cat_image_gray_corrected.ravel(), bins = 256, color = \"red\", alpha = 0.5, label = \"Corrected\")\n",
    "plt.xlim(0, 1)\n",
    "plt.title(\"Image histograms comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn.** Using the code above, display each image channel (1 row, 3 columns). Below each channel, show the histogram corresponding to that channel. Use the previous code pieces as a reference."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Write your code here"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8. Eigenvalues and Eigenvectors\n",
    "Some transformations are special. Let's examine this visually.\n",
    "\n",
    "Modify the code in the transformation visualization example. Instead of the two basis vectors, it should now accept **a vector as a parameter** and it should show that vector in the old and new coordinates. This should be simple enough to do :)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def visualize_transformed_vector(matrix, vec, title):\n",
    "    \"\"\"\n",
    "    Shows the vector (starting at (0; 0)) before and after the transformation\n",
    "    given by the specified matrix\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at the matrix given below:\n",
    "$$ T = \\begin{bmatrix}\n",
    "2 & -4 \\\\\n",
    "-1 & -1\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "See how the transformation acts on a arbitrary vector:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "matrix = np.array([[2, -4, 0], [-1, -1, 0], [0, 0, 1]])\n",
    "visualize_transformed_vector(matrix, [2, 3], \"Transformation\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it... transforms it somehow. Let's try another vector:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "visualize_transformed_vector(matrix, [-4, 1], \"Transformation\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm... the vector should be **scaled only**. That is, the entire matrix multiplication acts like a scalar multiplication for this special vector. Because it's so special, it's given a name - it's an **eigenvector** of that matrix. The factor which scales it is called an **eigenvalue** corresponding to that eigenvector.\n",
    "\n",
    "More formally, a vector $v$ is an eigenvector of the matrix $A$, corresponding to the eigenvalue $\\lambda$ if\n",
    "$$ Av = \\lambda v $$\n",
    "\n",
    "You can find more details about the computation [here](https://www.calvin.edu/~scofield/courses/m256/materials/eigenstuff.pdf).\n",
    "\n",
    "Why are these useful? For example, all of quantum physics is based on eigenvalues and eigenvectors. Also, it's very useful in **dimensionality reduction** problems. If you wish, you can explore that (for example, the principal component analysis algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Problem 9. Diffie - Hellman Key Exchange Simulation\n",
    "As we already saw, there are functions which are very easy to compute in the \"forward\" direction but really difficult (computationally) to invert (that is, determine the input from the output). There is a special case: the function may have a hidden \"trap door\". If you know where that door is, you can invert the function easily. This statement is at the core of modern cryptography.\n",
    "\n",
    "Look up **Diffie - Hellman key exchange** (here's a [video](https://www.youtube.com/watch?v=cM4mNVUBtHk) on that but feel free to use anything else you might find useful).\n",
    "\n",
    "Simulate the algorithm you just saw. Generate large enough numbers so the difference is noticeable (say, factoring takes 10-15 seconds). Simulate both participants in the key exchange. Simulate an eavesdropper.\n",
    "\n",
    "First, make sure after both participants run the algorithm, they have *the same key* (they generate the same number).\n",
    "\n",
    "Second, see how long it takes for them to exchange keys.\n",
    "\n",
    "Third, see how long it takes the eavesdropper to arrive at the correct shared secret.\n",
    "\n",
    "You should be able to see **the power of cryptography**. In this case, it's not that the function is irreversible. It can be reversed, but it takes a really long time (and with more bits, we're talking billions of years). However, if you know something else (this is called a **trap door**), the function becomes relatively easy to invert."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Problem 10. Principal Component Analysis\n",
    "Sometimes a projection of a higher-dimensional to a lower-dimensional space is useful. It's extremely useful if we want to get some visual understanding of a, say, 15D space, in 3D or even 2D. One algorithm which allows us to project multidimensional data into fewer dimensions **while keeping the most important shapes and structures** is called **principal component analysis** (PCA). You can explore this using the following checklist:\n",
    "* What are eigenvalues and eigenvectors?\n",
    "* What is the eigenbasis? What is the spectrum of a matrix?\n",
    "* How do we compute the eigenvalues and eigenvectors of a matrix?\n",
    "* What is projection?\n",
    "* How does projection conserve some shapes? Think about an object casting a shadow\n",
    "* How is the projection problem related to eigenvalues and eigenvectors?\n",
    "* What is PCA?\n",
    "* What are principal components? How many components are there (as a function of dimensions of the original space)?\n",
    "* What is variance? What is explained variance?\n",
    "* How do principal components relate to explained variance?\n",
    "* How is PCA implemented? Implement and show\n",
    "* Show some applications of PCA, e.g. reducing a 3D image to its first 2 principal components, plotting the 3D and 2D images\n",
    "* Show a practical use of PCA, for example, trying to see features in a 15D space, projected in 3D."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
